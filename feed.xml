<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://conor-13.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://conor-13.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-06-26T20:38:28+00:00</updated><id>https://conor-13.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Neural Network Training and Life Progress: Gradient Descent as a Life Framework</title><link href="https://conor-13.github.io/blog/2025/neural-network-training-and-human-progress/" rel="alternate" type="text/html" title="Neural Network Training and Life Progress: Gradient Descent as a Life Framework"/><published>2025-06-25T06:30:00+00:00</published><updated>2025-06-25T06:30:00+00:00</updated><id>https://conor-13.github.io/blog/2025/neural-network-training-and-human-progress</id><content type="html" xml:base="https://conor-13.github.io/blog/2025/neural-network-training-and-human-progress/"><![CDATA[<div align="center" style="font-weight: bold">Introduction</div> <p>Throughout the final year of my undergraduate degree at Princeton, I spent a lot of time thinking about how I could best approach the achievement of my goals and the realization of the evolving vision I devised for my life. I also spent a lot of time studying and training neural networks for my thesis. These threads of attention and cognitive effort largely felt orthogonal to one another: the former was strictly a personal and humanistic matter and the latter an impersonal and technical one. I compartmentalized the topics accordingly and never deliberately tried to connect them.</p> <p>Gradually and organically, however, I began to appreciate – or manufacture – their parallelism. The problem of transiting from my current state in life to my desired state in life, I realized, may not be dissimilar from the problem of transiting from a randomly-initialized neural network to one that is maximally performant at a given predictive or generative task. I became interested in translating the intuition I developed around how neural networks iteratively acquire their impressive capabilities into a mental framework for understanding and advancing my own journey.</p> <p>In this blog post, I present the product of these translational reflections. I first introduce and briefly explain the essence of gradient descent – the optimization algorithm through which neural networks learn. I then make the case that gradient descent is a powerful model for the process of making progress in one’s life. I conclude with some brief examples, mapping the framework I proposed in the previous section onto case studies.I hope the ideas I relay here are as useful to you as they have felt to me.</p> <div align="center" style="font-weight: bold">The Essence of Gradient Descent</div> <p>To explain the essence of gradient descent, I’ll start by constructing a model that represents the process of neural network training as simple interactions between simple computational objects.</p> <p>Suppose there is a list of numerical inputs <em>[x]</em> and a list of numerical outputs <em>[y]</em>. Suppose further that a function <em>f(x)</em> maps each numerical input in <em>[x]</em> to a numerical output in <em>[y]</em>. The objective is to train a neural network to predict <em>y</em> based on <em>x</em>, which essentially requires that the neural network learn <em>f(x)</em>.</p> <p>Accordingly, the neural network can be represented as <em>f’(x)</em> – an approximation of <em>f(x)</em>. Upon initialization, <em>f’(x)</em> is a random function that likely does not resemble <em>f(x)</em> at all. The instrument that is employed to change this – to minimize the difference between <em>f’(x)</em> and <em>f(x)</em> – is the gradient descent algorithm. Here’s how it works:</p> <ol> <li>Each element of <em>[x]</em> is passed through <em>f’(x)</em>, generating a prediction <em>y’</em>.</li> <li>The error between the predicted output <em>y’</em> and the true output <em>y</em> is calculated, as defined by a loss function.</li> <li>The derivative – the “gradient” – of the loss function with respect to the parameters that define <em>f’(x)</em> is calculated; this quantifies how directional alterations in <em>f’(x)</em> make <em>f’(x)</em> more similar or less similar to <em>f(x)</em>.</li> <li><em>f’(x)</em> is updated in the direction that reduces the value of the loss function and thus makes <em>f’(x)</em> more similar to <em>f(x)</em>. The magnitude of the update is governed by the value of the learning rate hyperparameter defined at the onset of training.</li> </ol> <p>These steps are repeated over several iterations until convergence, at which point <em>f’(x)</em> should closely resemble <em>f(x)</em>.</p> <p>This is gradient descent in the context of neural network training. Qualitatively, it is a procedure for minimizing the difference between the initial functionality of a neural network and the desired functionality of a neural network. I’ll reinforce these concepts in the next section as I adapt them into a framework for life progress.</p> <div align="center" style="font-weight: bold">Gradient Descent as a Life Framework</div> <p>I’ll make the case for gradient descent as a life framework by exchanging the mathematical objects on which the algorithm natively operates with the personal objects of progress; I’ll use the model I constructed in the previous section to explain this.</p> <p>Just as the objective of neural network training is to achieve a desired functionality within a neural network starting from a simple initialization, I posit that the objective of human progress is to reach a desired state in life from an initial state in life.</p> <p>Accomplishing this objective through one perfect, calculated action feels – and arguably is – infeasible, as is training an optimal neural network in one shot. Instead, a reasonable approach to progressing towards a desired state involves first taking an action; it involves first doing <em>something</em>, just as neural network training begins by randomly intializing the parameters of the network.</p> <p>The next step is to assess how far you are from accomplishing your goal after taking that action – to calculate the error between the result of your action and not your expected result but your North Star.</p> <p>What follows is analogous to the process of calculating the derivative of the loss function and updating the parameters of the network. You should determine which direction for your next action feels most aligned with your desired state and decide how risky an action you wish to take. The magnitude of risk is captured in the learning rate hyperparameter in neural network training.</p> <p>This process, I believe, is no different than vanilla gradient descent.</p>]]></content><author><name></name></author><category term="AI,"/><category term="Entrepreneurship"/><summary type="html"><![CDATA[I identify the parallelism between how neural networks learn and how individuals make progress in their lives.]]></summary></entry><entry><title type="html">Decision Trees and Human Collaboration</title><link href="https://conor-13.github.io/blog/2025/decision-trees-and-human-collaboration-copy/" rel="alternate" type="text/html" title="Decision Trees and Human Collaboration"/><published>2025-01-15T12:32:00+00:00</published><updated>2025-01-15T12:32:00+00:00</updated><id>https://conor-13.github.io/blog/2025/decision-trees-and-human-collaboration%20copy</id><content type="html" xml:base="https://conor-13.github.io/blog/2025/decision-trees-and-human-collaboration-copy/"><![CDATA[<p>My coursework sometimes piques my curiosity in ways likely unintended. When I learn a new concept in class, for example, it sometimes interests me not academically but translationally. I become intrigued by how the concept offers wisdom to domains totally outside that from which it came, and I find it satisfying to think through these incidental connections, even if they are contrived, elementary, and imprecise.</p> <p>This experience was surprisingly frequent this semester. While taking courses on machine learning, organic chemistry, ecology, and evolutionary biology, I came upon several translational lessons I believe are worth sharing here. I proceed here by describing from a machine learning course the first of these lessons and the concepts that underlie it. I describe what we can learn about human collaboration by studying decision tree ensembles.</p> <div align="center" style="font-weight: bold">Decision Tree Ensembles -- How to Make Good Decisions in Collaboration</div> <p><br/> The decision tree architecture learns to predict a target feature value by determining hierachically which compositions of descriptive feature values correspond to which target feature values in a training dataset. A single decision tree by itself can model complex relationships, but several such decision trees can be ensembled into an aggregate model with a greater representational capacity.</p> <p>In <em>Fundamentals of Machine Learning for Predictive Data Analytics</em>, authors Kelleher et al. state a heuristic condition on the effectiveness of ensembling: for an ensemble to be more performant than one of its members, each member of the ensemble should be distinct. The intuition behind this condition is fairly straightforward: if each member of the ensemble is not sufficiently distinct, then the ensemble’s inferences could be generated by just one of its members (i.e., an ensemble would possess no significant advantage over any one of its members). In this sense, an ensemble with significant redundancy across its members engages in “group think,” amplifying the homogeneous biases of its membership.</p> <p>Kelleher et al. briefly mention that this principle applies equally to ensembles of humans - a suggestion that has captivated me since I first read it. As I interpret it, this comment lends itself to a theory of collaboration which implies that, in general, strong and productive human organizations will consist of individuals that (1) approach problems differently, (2) are independently competent, and (3) are tuned to the same objective. As I have realized, it is the synergy between these qualities - not the isolated merit of each individual quality - that is powerful. Why each of these qualities alone is insufficient and why each pair of these qualities is weaker without the third can be understood through the following analysis. The effectiveness of an organization is improbable (or the collaboration it houses is unjustifiable) when:</p> <ul> <li>Its members approach problems differently but each approach leads to poor results (i.e., members are not independently competent) or each approach achieves conflicting ends (i.e., members are not tuned to the same objecive).</li> <li>Its members are independently competent but are redundant in their methodology (i.e., members do not approach problems differently) or possess radically different ambitions (i.e., members are not tuned to the same objective).</li> <li>Its members are tuned to the same objective but pursue that objective in identical ways (i.e., members do not approach problems differently) or pursue that objective ineffectively (i.e., members are not independently competent).</li> </ul> <p>Note: The independent competence argument can be overturned if the absence of independent competence is accompanied by collaborative competence, though it is arguable that independent competence is necessary for the latter. Regardless, this is an edge case I will ignore here.</p> <p>I find this connection satisfying and translational because the basic criteria for an effective ensemble of decision trees can be extended into a set of criteria that retroactively help to explain why the “good” teams I’ve been on were “good” and why the “bad” teams I’ve been on were “bad.” The way I now understand and approach organized collaboration has tranformed due to these insights.</p>]]></content><author><name></name></author><category term="AI,"/><category term="Entrepreneurship"/><summary type="html"><![CDATA[I describe what we can learn about human collaboration by studying decision tree ensembles.]]></summary></entry></feed>