<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://conor-13.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://conor-13.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-01-21T01:16:15+00:00</updated><id>https://conor-13.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Decision Trees and Human Collaboration</title><link href="https://conor-13.github.io/blog/2025/decision-trees-and-human-collaboration/" rel="alternate" type="text/html" title="Decision Trees and Human Collaboration"/><published>2025-01-15T12:32:00+00:00</published><updated>2025-01-15T12:32:00+00:00</updated><id>https://conor-13.github.io/blog/2025/decision-trees-and-human-collaboration</id><content type="html" xml:base="https://conor-13.github.io/blog/2025/decision-trees-and-human-collaboration/"><![CDATA[<p>My coursework sometimes piques my curiosity in ways likely unintended. When I learn a new concept in class, for example, it sometimes interests me not academically but translationally. I become intrigued by how the concept offers wisdom to domains totally outside that from which it came, and I find it satisfying to think through these incidental connections, even if they are contrived, elementary, and imprecise.</p> <p>This experience was surprisingly frequent this semester. While taking courses on machine learning, organic chemistry, ecology, and evolutionary biology, I came upon several tranlational lessons I believe are worth sharing here. I proceed here by describing from a machine learning course the first of these lessons and the concepts that underlie it. I describe what we can learn about human collaboration by studying decision tree ensembles.</p> <div align="center" style="font-weight: bold">Decision Tree Ensembles -- How to Make Good Decisions in Collaboration</div> <p><br/> The decision tree architecture learns to predict a target feature value by determining hierachically which compositions of descriptive feature values correspond to which target feature values in a training dataset. A single decision tree by itself can model complex relationships, but several such decision trees can be ensembled into an aggregate model with a greater representational capacity.</p> <p>In <em>Fundamentals of Machine Learning for Predictive Data Analytics</em>, authors Kelleher et al. state a heuristic condition on the effectiveness of ensembling: for an ensemble to be more performant than one of its members, each member of the ensemble should be distinct. The intuition behind this condition is fairly straightforward: if each member of the ensemble is not sufficiently distinct, then the ensemble’s inferences could be generated by just one of its members (i.e., an ensemble would possess no significant advantage over any one of its members). In this sense, an ensemble with significant redundancy across its members engages in “group think,” amplifying the homogeneous biases of its membership.</p> <p>Kelleher et al. briefly mention that this principle applies equally to ensembles of humans - a suggestion that has captivated me since I first read it. As I interpret it, this comment lends itself to a theory of collaboration which implies that, in general, strong and productive human organizations will consist of individuals that (1) approach problems differently, (2) are independently competent, and (3) are tuned to the same objective. As I have realized, it is the synergy between these qualities - not the isolated merit of each individual quality - that is powerful. Why each of these qualities alone is insufficient and why each pair of these qualities is weaker without the third can be understood through the following analysis. The effectiveness of an organization is improbable (or the collaboration it houses is unjustifiable) when:</p> <ul> <li>Its members approach problems differently but each approach leads to poor results (i.e., members are not independently competent) or each approach achieves conflicting ends (i.e., members are not tuned to the same objecive).</li> <li>Its members are independently competent but are redundant in their methodology (i.e., members do not approach problems differently) or possess radically different ambitions (i.e., members are not tuned to the same objective).</li> <li>Its members are tuned to the same objective but pursue that objective in identical ways (i.e., members do not approach problems differently) or pursue that objective ineffectively (i.e., members are not independently competent).</li> </ul> <p>Note: The independent competence argument can be overturned if the absence of independent competence is accompanied by collaborative competence, though it is arguable that independent competence is necessary for the latter. Regardless, this is an edge case I will ignore here.</p> <p>I find this connection satisfying and translational because the basic criteria for an effective ensemble of decision trees can be extended into a set of criteria that retroactively help to explain why the “good” teams I’ve been on were “good” and why the bad teams I’ve been on were “bad.” The way I now understand and approach organized collaboration has tranformed due to these insights.</p>]]></content><author><name></name></author><category term="Connections"/><summary type="html"><![CDATA[I describe what we can learn about human collaboration by studying decision tree ensembles.]]></summary></entry></feed>