---
layout: post
title: The Incentives of AI Makers, Models, and Middlemen
date: 2025-05-29 9:00:00

description: I examine the incentives of stakeholders in the contemporary AI flywheel to distinguish promotional hype from impactful progress.
tags: Connections
---
During my final undergraduate semester at Princeton University, I took a political science course titled *International Organizations* with Professor James Vreeland. In surveying institutions like the International Monetary Fund, the World Bank, and the United Nations, the course very frequently examined the incentives of organizational agents and member states to explain the extent to which such organizations have or have not achieved success in realizing their stated objectives. I've since become fascinated with incentives, and I now instinctively leverage their explanatory power to critically evaluate the opinions I read on the topics that interest me.

Accordingly, in recent months I've thought much about the incentives of the stakeholders of the AI ecosystems to rationalize the apparent disparity between the hysteria surrounding AI and its observable impact.  

<div align="center" style="font-weight: bold">Decision Tree Ensembles -- How to Make Good Decisions in Collaboration</div> <br>
   The decision tree architecture learns to predict a target feature value by determining hierachically which compositions of descriptive feature values correspond to which target feature values in a training dataset. A single decision tree by itself can model complex relationships, but several such decision trees can be ensembled into and aggregate model with a greater representational capacity. 
   
   In *Fundamentals of Machine Learning for Predictive Data Analytics*, authors Kelleher et al. state a heuristic condition on the effectiveness of ensembling: for an ensemble to be more performant than one of its members, each member of the ensemble should be distinct. The intuition behind this condition is fairly straightforward: if each member of the ensemble is not sufficiently distinct, then the ensemble's inferences could be generated by just one of its members (i.e., an ensemble would possess no significant advantage over any one of its members). In this sense, an ensemble with significant redundancy across its members engages in "group think," amplifying the homogeneous biases of its membership. 
   
   Kelleher et al. briefly mention that this principle applies equally to ensembles of humans - a suggestion that has captivated me since I first read it. As I interpret it, this comment lends itself to a theory of collaboration which implies that, in general, strong and productive human organizations will consist of individuals that (1) approach problems differently, (2) are independently competent, and (3) are tuned to the same objective. As I have realized, it is the synergy between these qualities - not the isolated merit of each individual quality - that is powerful. Why each of these qualities alone is insufficient and why each pair of these qualities is weaker without the third can be understood through the following analysis. The effectiveness of an organization is improbable (or the collaboration it houses is unjustifiable) when:
   - Its members approach problems differently but each approach leads to poor results (i.e., members are not independently competent) or each approach achieves conflicting ends (i.e., members are not tuned to the same objecive).
   - Its members are independently competent but are redundant in their methodology (i.e., members do not approach problems differently) or possess radically different ambitions (i.e., members are not tuned to the same objective).
   - Its members are tuned to the same objective but pursue that objective in identical ways (i.e., members do not approach problems differently) or pursue that objective ineffectively (i.e., members are not independently competent).

  Note: The independent competence argument can be overturned if the absence of independent competence is accompanied by collaborative competence, though it is arguable that independent competence is necessary for the latter. Regardless, this is an edge case I will ignore here.
   
   
  I find this connection satisfying and translational because the basic criteria for an effective ensemble of decision trees can be extended into a set of criteria that retroactively help to explain why the "good" teams I've been on were "good" and why the "bad" teams I've been on were "bad." The way I now understand and approach organized collaboration has tranformed due to these insights.
  

